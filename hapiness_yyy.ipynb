{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "import os\n",
    "from sklearn.linear_model import BayesianRidge as br\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.linear_model import ElasticNet as en\n",
    "from sklearn.kernel_ridge import KernelRidge as kr\n",
    "from sklearn.model_selection import  KFold, StratifiedKFold,GroupKFold, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"happiness_train_complete.csv\", parse_dates=['survey_time'],encoding='latin-1') \n",
    "test = pd.read_csv(\"happiness_test_complete.csv\", parse_dates=['survey_time'],encoding='latin-1') #latin-1向下兼容ASCII\n",
    "train = train[train[\"happiness\"]!=-8].reset_index(drop=True)\n",
    "train_data_copy = train.copy() #删去\"happiness\" 为-8的行\n",
    "target_col = \"happiness\" #目标列\n",
    "target = train_data_copy[target_col]\n",
    "del train_data_copy[target_col] #去除目标列\n",
    "\n",
    "data = pd.concat([train_data_copy,test],axis=0,ignore_index=True)\n",
    "# print(train['survey_time'])\n",
    "# print(train['survey_time'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7988.000000\n",
       "mean        3.867927\n",
       "std         0.818717\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.happiness.describe() #数据的基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make feature +5\n",
    "#csv中有复数值：-1、-2、-3、-8，将他们视为有问题的特征，但是不删去\n",
    "def getres1(row):\n",
    "    return len([x for x in row.values if type(x)==int and x<0])\n",
    "\n",
    "def getres2(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-8])\n",
    "\n",
    "def getres3(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-1])\n",
    "\n",
    "def getres4(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-2])\n",
    "\n",
    "def getres5(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-3])\n",
    "\n",
    "#检查数据\n",
    "data['neg1'] = data[data.columns].apply(lambda row:getres1(row),axis=1)\n",
    "data.loc[data['neg1']>20,'neg1'] = 20  #平滑处理,最多出现20次\n",
    "\n",
    "data['neg2'] = data[data.columns].apply(lambda row:getres2(row),axis=1)\n",
    "data['neg3'] = data[data.columns].apply(lambda row:getres3(row),axis=1)\n",
    "data['neg4'] = data[data.columns].apply(lambda row:getres4(row),axis=1)\n",
    "data['neg5'] = data[data.columns].apply(lambda row:getres5(row),axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填充缺失值 共25列 去掉4列 填充21列\n",
    "#以下的列都是缺省的，视情况填补\n",
    "data['work_status'] = data['work_status'].fillna(0)\n",
    "data['work_yr'] = data['work_yr'].fillna(0)\n",
    "data['work_manage'] = data['work_manage'].fillna(0)\n",
    "data['work_type'] = data['work_type'].fillna(0)\n",
    "\n",
    "data['edu_yr'] = data['edu_yr'].fillna(0)\n",
    "data['edu_status'] = data['edu_status'].fillna(0)\n",
    "\n",
    "data['s_work_type'] = data['s_work_type'].fillna(0)\n",
    "data['s_work_status'] = data['s_work_status'].fillna(0)\n",
    "data['s_political'] = data['s_political'].fillna(0)\n",
    "data['s_hukou'] = data['s_hukou'].fillna(0)\n",
    "data['s_income'] = data['s_income'].fillna(0)\n",
    "data['s_birth'] = data['s_birth'].fillna(0)\n",
    "data['s_edu'] = data['s_edu'].fillna(0)\n",
    "data['s_work_exper'] = data['s_work_exper'].fillna(0)\n",
    "\n",
    "data['minor_child'] = data['minor_child'].fillna(0)\n",
    "data['marital_now'] = data['marital_now'].fillna(0)\n",
    "data['marital_1st'] = data['marital_1st'].fillna(0)\n",
    "data['social_neighbor']=data['social_neighbor'].fillna(0)\n",
    "data['social_friend']=data['social_friend'].fillna(0)\n",
    "data['hukou_loc']=data['hukou_loc'].fillna(1) #最少为1，表示户口\n",
    "data['family_income']=data['family_income'].fillna(66365) #删除问题值后的平均值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10956, 272)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_type</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>depression/age</th>\n",
       "      <th>floor_area/age</th>\n",
       "      <th>health/age</th>\n",
       "      <th>class_10_diff/age</th>\n",
       "      <th>class/age</th>\n",
       "      <th>health_problem/age</th>\n",
       "      <th>family_status/age</th>\n",
       "      <th>leisure_sum/age</th>\n",
       "      <th>public_service_sum/age</th>\n",
       "      <th>trust_sum/age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285211</td>\n",
       "      <td>0.410351</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.724620</td>\n",
       "      <td>0.666638</td>\n",
       "      <td>0.925941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.952824</td>\n",
       "      <td>1.179337</td>\n",
       "      <td>1.012552</td>\n",
       "      <td>1.344444</td>\n",
       "      <td>0.891344</td>\n",
       "      <td>1.359551</td>\n",
       "      <td>1.011792</td>\n",
       "      <td>1.130778</td>\n",
       "      <td>1.188442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343537</td>\n",
       "      <td>0.972328</td>\n",
       "      <td>1.150485</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>1.195762</td>\n",
       "      <td>1.055679</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>0.966470</td>\n",
       "      <td>1.193204</td>\n",
       "      <td>0.803693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111663</td>\n",
       "      <td>0.642329</td>\n",
       "      <td>1.276353</td>\n",
       "      <td>4.977778</td>\n",
       "      <td>1.199143</td>\n",
       "      <td>1.188329</td>\n",
       "      <td>1.162630</td>\n",
       "      <td>0.899346</td>\n",
       "      <td>1.153810</td>\n",
       "      <td>1.300950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.587284</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>1.116803</td>\n",
       "      <td>1.093645</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>0.728161</td>\n",
       "      <td>1.117428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  survey_type  province  city  county  survey_time  gender  birth  \\\n",
       "0   1            1        12    32      59         2015       1   1959   \n",
       "1   2            2        18    52      85         2015       1   1992   \n",
       "2   3            2        29    83     126         2015       2   1967   \n",
       "3   4            2        10    28      51         2015       2   1943   \n",
       "4   5            1         7    18      36         2015       2   1994   \n",
       "\n",
       "   nationality  religion  ...  depression/age  floor_area/age health/age  \\\n",
       "0            1         1  ...        1.285211        0.410351   0.848837   \n",
       "1            1         1  ...        0.733333        0.952824   1.179337   \n",
       "2            1         0  ...        1.343537        0.972328   1.150485   \n",
       "3            1         1  ...        1.111663        0.642329   1.276353   \n",
       "4            1         1  ...        0.750000        0.587284   1.177106   \n",
       "\n",
       "   class_10_diff/age  class/age  health_problem/age  family_status/age  \\\n",
       "0           0.000000   0.683307            0.521429           0.733668   \n",
       "1           1.012552   1.344444            0.891344           1.359551   \n",
       "2           1.190955   1.195762            1.055679           1.190955   \n",
       "3           4.977778   1.199143            1.188329           1.162630   \n",
       "4           0.000000   0.236957            1.116803           1.093645   \n",
       "\n",
       "   leisure_sum/age  public_service_sum/age  trust_sum/age  \n",
       "0         0.724620                0.666638       0.925941  \n",
       "1         1.011792                1.130778       1.188442  \n",
       "2         0.966470                1.193204       0.803693  \n",
       "3         0.899346                1.153810       1.300950  \n",
       "4         1.045313                0.728161       1.117428  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#144+1 =145\n",
    "#继续进行特殊的列进行数据处理\n",
    "#读happiness_index.xlsx\n",
    "data['survey_time'] = pd.to_datetime(data['survey_time'], format='%Y-%m-%d',errors='coerce')#防止时间格式不同的报错errors='coerce‘\n",
    "data['survey_time'] = data['survey_time'].dt.year #仅仅是year，方便计算年龄\n",
    "data['age'] = data['survey_time']-data['birth']\n",
    "# print(data['age'],data['survey_time'],data['birth'])\n",
    "#年龄分层 145+1=146\n",
    "bins = [0,17,26,34,50,63,100]\n",
    "data['age_bin'] = pd.cut(data['age'], bins, labels=[0,1,2,3,4,5]) \n",
    "#对‘宗教’处理\n",
    "data.loc[data['religion']<0,'religion'] = 1 #1为不信仰宗教\n",
    "data.loc[data['religion_freq']<0,'religion_freq'] = 1 #1为从来没有参加过\n",
    "#对‘教育程度’处理\n",
    "data.loc[data['edu']<0,'edu'] = 4 #初中\n",
    "data.loc[data['edu_status']<0,'edu_status'] = 0\n",
    "data.loc[data['edu_yr']<0,'edu_yr'] = 0\n",
    "#对‘个人收入’处理\n",
    "data.loc[data['income']<0,'income'] = 0 #认为无收入\n",
    "#对‘政治面貌’处理\n",
    "data.loc[data['political']<0,'political'] = 1 #认为是群众\n",
    "#对体重处理\n",
    "data.loc[(data['weight_jin']<=80)&(data['height_cm']>=160),'weight_jin']= data['weight_jin']*2\n",
    "data.loc[data['weight_jin']<=60,'weight_jin']= data['weight_jin']*2  #个人的想法，哈哈哈，没有60斤的成年人吧\n",
    "#对身高处理\n",
    "data.loc[data['height_cm']<150,'height_cm'] = 150 #成年人的实际情况\n",
    "#对‘健康’处理\n",
    "data.loc[data['health']<0,'health'] = 4 #认为是比较健康\n",
    "data.loc[data['health_problem']<0,'health_problem'] = 4\n",
    "#对‘沮丧’处理\n",
    "data.loc[data['depression']<0,'depression'] = 4 #一般人都是很少吧\n",
    "#对‘媒体’处理\n",
    "data.loc[data['media_1']<0,'media_1'] = 1 #都是从不\n",
    "data.loc[data['media_2']<0,'media_2'] = 1\n",
    "data.loc[data['media_3']<0,'media_3'] = 1\n",
    "data.loc[data['media_4']<0,'media_4'] = 1\n",
    "data.loc[data['media_5']<0,'media_5'] = 1\n",
    "data.loc[data['media_6']<0,'media_6'] = 1\n",
    "#对‘空闲活动’处理\n",
    "data.loc[data['leisure_1']<0,'leisure_1'] = 1 #都是根据自己的想法\n",
    "data.loc[data['leisure_2']<0,'leisure_2'] = 5\n",
    "data.loc[data['leisure_3']<0,'leisure_3'] = 3\n",
    "data.loc[data['leisure_4']<0,'leisure_4'] = data['leisure_4'].mode() #取众数\n",
    "data.loc[data['leisure_5']<0,'leisure_5'] = data['leisure_5'].mode()\n",
    "data.loc[data['leisure_6']<0,'leisure_6'] = data['leisure_6'].mode()\n",
    "data.loc[data['leisure_7']<0,'leisure_7'] = data['leisure_7'].mode()\n",
    "data.loc[data['leisure_8']<0,'leisure_8'] = data['leisure_8'].mode()\n",
    "data.loc[data['leisure_9']<0,'leisure_9'] = data['leisure_9'].mode()\n",
    "data.loc[data['leisure_10']<0,'leisure_10'] = data['leisure_10'].mode()\n",
    "data.loc[data['leisure_11']<0,'leisure_11'] = data['leisure_11'].mode()\n",
    "data.loc[data['leisure_12']<0,'leisure_12'] = data['leisure_12'].mode()\n",
    "data.loc[data['socialize']<0,'socialize'] = 2 #很少\n",
    "data.loc[data['relax']<0,'relax'] = 4 #经常\n",
    "data.loc[data['learn']<0,'learn'] = 1 #从不，哈哈哈哈\n",
    "#对‘社交’处理\n",
    "data.loc[data['social_neighbor']<0,'social_neighbor'] = 0\n",
    "data.loc[data['social_friend']<0,'social_friend'] = 0\n",
    "data.loc[data['socia_outing']<0,'socia_outing'] = 1\n",
    "data.loc[data['neighbor_familiarity']<0,'social_neighbor']= 4\n",
    "#对‘社会公平性’处理\n",
    "data.loc[data['equity']<0,'equity'] = 4\n",
    "#对‘社会等级’处理\n",
    "data.loc[data['class_10_before']<0,'class_10_before'] = 3\n",
    "data.loc[data['class']<0,'class'] = 5\n",
    "data.loc[data['class_10_after']<0,'class_10_after'] = 5\n",
    "data.loc[data['class_14']<0,'class_14'] = 2\n",
    "#对‘工作情况’处理\n",
    "data.loc[data['work_status']<0,'work_status'] = 0\n",
    "data.loc[data['work_yr']<0,'work_yr'] = 0\n",
    "data.loc[data['work_manage']<0,'work_manage'] = 0\n",
    "data.loc[data['work_type']<0,'work_type'] = 0\n",
    "#对‘社会保障’处理\n",
    "data.loc[data['insur_1']<0,'insur_1'] = 1\n",
    "data.loc[data['insur_2']<0,'insur_2'] = 1\n",
    "data.loc[data['insur_3']<0,'insur_3'] = 1\n",
    "data.loc[data['insur_4']<0,'insur_4'] = 1\n",
    "data.loc[data['insur_1']==0,'insur_1'] = 0\n",
    "data.loc[data['insur_2']==0,'insur_2'] = 0\n",
    "data.loc[data['insur_3']==0,'insur_3'] = 0\n",
    "data.loc[data['insur_4']==0,'insur_4'] = 0\n",
    "\n",
    "#对家庭情况处理\n",
    "family_income_mean = data['family_income'].mean()\n",
    "data.loc[data['family_income']<0,'family_income'] = family_income_mean\n",
    "data.loc[data['family_m']<0,'family_m'] = 2\n",
    "data.loc[data['family_status']<0,'family_status'] = 3\n",
    "data.loc[data['house']<0,'house'] = 1\n",
    "data.loc[data['car']<0,'car'] = 0\n",
    "data.loc[data['car']==2,'car'] = 0\n",
    "data.loc[data['son']<0,'son'] = 1\n",
    "data.loc[data['daughter']<0,'daughter'] = 0\n",
    "data.loc[data['minor_child']<0,'minor_child'] = 0\n",
    "#对‘婚姻’处理\n",
    "data.loc[data['marital_1st']<0,'marital_1st'] = 0\n",
    "data.loc[data['marital_now']<0,'marital_now'] = 0\n",
    "#对‘配偶’处理\n",
    "data.loc[data['s_birth']<0,'s_birth'] = 0\n",
    "data.loc[data['s_edu']<0,'s_edu'] = 0\n",
    "data.loc[data['s_political']<0,'s_political'] = 0\n",
    "data.loc[data['s_hukou']<0,'s_hukou'] = 0\n",
    "data.loc[data['s_income']<0,'s_income'] = 0\n",
    "data.loc[data['s_work_type']<0,'s_work_type'] = 0\n",
    "data.loc[data['s_work_status']<0,'s_work_status'] = 0\n",
    "data.loc[data['s_work_exper']<0,'s_work_exper'] = 0\n",
    "#对‘父母情况’处理\n",
    "data.loc[data['f_birth']<0,'f_birth'] = 1945\n",
    "data.loc[data['f_edu']<0,'f_edu'] = 1\n",
    "data.loc[data['f_political']<0,'f_political'] = 1\n",
    "data.loc[data['f_work_14']<0,'f_work_14'] = 2\n",
    "data.loc[data['m_birth']<0,'m_birth'] = 1940\n",
    "data.loc[data['m_edu']<0,'m_edu'] = 1\n",
    "data.loc[data['m_political']<0,'m_political'] = 1\n",
    "data.loc[data['m_work_14']<0,'m_work_14'] = 2\n",
    "#和同龄人相比社会经济地位\n",
    "data.loc[data['status_peer']<0,'status_peer'] = 2\n",
    "#和3年前比社会经济地位\n",
    "data.loc[data['status_3_before']<0,'status_3_before'] = 2\n",
    "#对‘观点’处理\n",
    "data.loc[data['view']<0,'view'] = 4\n",
    "#对期望年收入处理\n",
    "data.loc[data['inc_ability']<=0,'inc_ability']= 2\n",
    "inc_exp_mean = data['inc_exp'].mean()\n",
    "data.loc[data['inc_exp']<=0,'inc_exp']= inc_exp_mean #取均值\n",
    "\n",
    "#部分特征处理，取众数\n",
    "for i in range(1,9+1):\n",
    "    data.loc[data['public_service_'+str(i)]<0,'public_service_'+str(i)] = data['public_service_'+str(i)].dropna().mode().values\n",
    "for i in range(1,13+1):\n",
    "    data.loc[data['trust_'+str(i)]<0,'trust_'+str(i)] = data['trust_'+str(i)].dropna().mode().values\n",
    "\n",
    "#第一次结婚年龄 147\n",
    "data['marital_1stbir'] = data['marital_1st'] - data['birth'] \n",
    "#最近结婚年龄 148\n",
    "data['marital_nowtbir'] = data['marital_now'] - data['birth'] \n",
    "#是否再婚 149\n",
    "data['mar'] = data['marital_nowtbir'] - data['marital_1stbir']\n",
    "#配偶年龄 150\n",
    "data['marital_sbir'] = data['marital_now']-data['s_birth']\n",
    "#配偶年龄差 151\n",
    "data['age_'] = data['marital_nowtbir'] - data['marital_sbir'] \n",
    "\n",
    "#收入比 151+7 =158\n",
    "data['income/s_income'] = data['income']/(data['s_income']+1)\n",
    "data['income+s_income'] = data['income']+(data['s_income']+1)\n",
    "data['income/family_income'] = data['income']/(data['family_income']+1)\n",
    "data['all_income/family_income'] = (data['income']+data['s_income'])/(data['family_income']+1)\n",
    "data['income/inc_exp'] = data['income']/(data['inc_exp']+1)\n",
    "data['family_income/m'] = data['family_income']/(data['family_m']+0.01)\n",
    "data['income/m'] = data['income']/(data['family_m']+0.01)\n",
    "\n",
    "#收入/面积比 158+4=162\n",
    "data['income/floor_area'] = data['income']/(data['floor_area']+0.01)\n",
    "data['all_income/floor_area'] = (data['income']+data['s_income'])/(data['floor_area']+0.01)\n",
    "data['family_income/floor_area'] = data['family_income']/(data['floor_area']+0.01)\n",
    "data['floor_area/m'] = data['floor_area']/(data['family_m']+0.01)\n",
    "\n",
    "#class 162+3=165\n",
    "data['class_10_diff'] = (data['class_10_after'] - data['class'])\n",
    "data['class_diff'] = data['class'] - data['class_10_before']\n",
    "data['class_14_diff'] = data['class'] - data['class_14']\n",
    "#悠闲指数 166\n",
    "leisure_fea_lis = ['leisure_'+str(i) for i in range(1,13)]\n",
    "data['leisure_sum'] = data[leisure_fea_lis].sum(axis=1) #skew\n",
    "#满意指数 167\n",
    "public_service_fea_lis = ['public_service_'+str(i) for i in range(1,10)]\n",
    "data['public_service_sum'] = data[public_service_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "#信任指数 168\n",
    "trust_fea_lis = ['trust_'+str(i) for i in range(1,14)]\n",
    "data['trust_sum'] = data[trust_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "#province mean 168+13=181\n",
    "data['province_income_mean'] = data.groupby(['province'])['income'].transform('mean').values\n",
    "data['province_family_income_mean'] = data.groupby(['province'])['family_income'].transform('mean').values\n",
    "data['province_equity_mean'] = data.groupby(['province'])['equity'].transform('mean').values\n",
    "data['province_depression_mean'] = data.groupby(['province'])['depression'].transform('mean').values\n",
    "data['province_floor_area_mean'] = data.groupby(['province'])['floor_area'].transform('mean').values\n",
    "data['province_health_mean'] = data.groupby(['province'])['health'].transform('mean').values\n",
    "data['province_class_10_diff_mean'] = data.groupby(['province'])['class_10_diff'].transform('mean').values\n",
    "data['province_class_mean'] = data.groupby(['province'])['class'].transform('mean').values\n",
    "data['province_health_problem_mean'] = data.groupby(['province'])['health_problem'].transform('mean').values\n",
    "data['province_family_status_mean'] = data.groupby(['province'])['family_status'].transform('mean').values\n",
    "data['province_leisure_sum_mean'] = data.groupby(['province'])['leisure_sum'].transform('mean').values\n",
    "data['province_public_service_sum_mean'] = data.groupby(['province'])['public_service_sum'].transform('mean').values\n",
    "data['province_trust_sum_mean'] = data.groupby(['province'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#city   mean 181+13=194\n",
    "data['city_income_mean'] = data.groupby(['city'])['income'].transform('mean').values\n",
    "data['city_family_income_mean'] = data.groupby(['city'])['family_income'].transform('mean').values\n",
    "data['city_equity_mean'] = data.groupby(['city'])['equity'].transform('mean').values\n",
    "data['city_depression_mean'] = data.groupby(['city'])['depression'].transform('mean').values\n",
    "data['city_floor_area_mean'] = data.groupby(['city'])['floor_area'].transform('mean').values\n",
    "data['city_health_mean'] = data.groupby(['city'])['health'].transform('mean').values\n",
    "data['city_class_10_diff_mean'] = data.groupby(['city'])['class_10_diff'].transform('mean').values\n",
    "data['city_class_mean'] = data.groupby(['city'])['class'].transform('mean').values\n",
    "data['city_health_problem_mean'] = data.groupby(['city'])['health_problem'].transform('mean').values\n",
    "data['city_family_status_mean'] = data.groupby(['city'])['family_status'].transform('mean').values\n",
    "data['city_leisure_sum_mean'] = data.groupby(['city'])['leisure_sum'].transform('mean').values\n",
    "data['city_public_service_sum_mean'] = data.groupby(['city'])['public_service_sum'].transform('mean').values\n",
    "data['city_trust_sum_mean'] = data.groupby(['city'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#county  mean 194 + 13 = 207\n",
    "data['county_income_mean'] = data.groupby(['county'])['income'].transform('mean').values\n",
    "data['county_family_income_mean'] = data.groupby(['county'])['family_income'].transform('mean').values\n",
    "data['county_equity_mean'] = data.groupby(['county'])['equity'].transform('mean').values\n",
    "data['county_depression_mean'] = data.groupby(['county'])['depression'].transform('mean').values\n",
    "data['county_floor_area_mean'] = data.groupby(['county'])['floor_area'].transform('mean').values\n",
    "data['county_health_mean'] = data.groupby(['county'])['health'].transform('mean').values\n",
    "data['county_class_10_diff_mean'] = data.groupby(['county'])['class_10_diff'].transform('mean').values\n",
    "data['county_class_mean'] = data.groupby(['county'])['class'].transform('mean').values\n",
    "data['county_health_problem_mean'] = data.groupby(['county'])['health_problem'].transform('mean').values\n",
    "data['county_family_status_mean'] = data.groupby(['county'])['family_status'].transform('mean').values\n",
    "data['county_leisure_sum_mean'] = data.groupby(['county'])['leisure_sum'].transform('mean').values\n",
    "data['county_public_service_sum_mean'] = data.groupby(['county'])['public_service_sum'].transform('mean').values\n",
    "data['county_trust_sum_mean'] = data.groupby(['county'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#ratio 相比同省 207 + 13 =220\n",
    "data['income/province'] = data['income']/(data['province_income_mean'])                                      \n",
    "data['family_income/province'] = data['family_income']/(data['province_family_income_mean'])   \n",
    "data['equity/province'] = data['equity']/(data['province_equity_mean'])       \n",
    "data['depression/province'] = data['depression']/(data['province_depression_mean'])                                                \n",
    "data['floor_area/province'] = data['floor_area']/(data['province_floor_area_mean'])\n",
    "data['health/province'] = data['health']/(data['province_health_mean'])\n",
    "data['class_10_diff/province'] = data['class_10_diff']/(data['province_class_10_diff_mean'])\n",
    "data['class/province'] = data['class']/(data['province_class_mean'])\n",
    "data['health_problem/province'] = data['health_problem']/(data['province_health_problem_mean'])\n",
    "data['family_status/province'] = data['family_status']/(data['province_family_status_mean'])\n",
    "data['leisure_sum/province'] = data['leisure_sum']/(data['province_leisure_sum_mean'])\n",
    "data['public_service_sum/province'] = data['public_service_sum']/(data['province_public_service_sum_mean'])\n",
    "data['trust_sum/province'] = data['trust_sum']/(data['province_trust_sum_mean']+1)\n",
    "\n",
    "#ratio 相比同市 220 + 13 =233\n",
    "data['income/city'] = data['income']/(data['city_income_mean'])                                      \n",
    "data['family_income/city'] = data['family_income']/(data['city_family_income_mean'])   \n",
    "data['equity/city'] = data['equity']/(data['city_equity_mean'])       \n",
    "data['depression/city'] = data['depression']/(data['city_depression_mean'])                                                \n",
    "data['floor_area/city'] = data['floor_area']/(data['city_floor_area_mean'])\n",
    "data['health/city'] = data['health']/(data['city_health_mean'])\n",
    "data['class_10_diff/city'] = data['class_10_diff']/(data['city_class_10_diff_mean'])\n",
    "data['class/city'] = data['class']/(data['city_class_mean'])\n",
    "data['health_problem/city'] = data['health_problem']/(data['city_health_problem_mean'])\n",
    "data['family_status/city'] = data['family_status']/(data['city_family_status_mean'])\n",
    "data['leisure_sum/city'] = data['leisure_sum']/(data['city_leisure_sum_mean'])\n",
    "data['public_service_sum/city'] = data['public_service_sum']/(data['city_public_service_sum_mean'])\n",
    "data['trust_sum/city'] = data['trust_sum']/(data['city_trust_sum_mean'])\n",
    "\n",
    "#ratio 相比同个地区 233 + 13 =246\n",
    "data['income/county'] = data['income']/(data['county_income_mean'])                                      \n",
    "data['family_income/county'] = data['family_income']/(data['county_family_income_mean'])   \n",
    "data['equity/county'] = data['equity']/(data['county_equity_mean'])       \n",
    "data['depression/county'] = data['depression']/(data['county_depression_mean'])                                                \n",
    "data['floor_area/county'] = data['floor_area']/(data['county_floor_area_mean'])\n",
    "data['health/county'] = data['health']/(data['county_health_mean'])\n",
    "data['class_10_diff/county'] = data['class_10_diff']/(data['county_class_10_diff_mean'])\n",
    "data['class/county'] = data['class']/(data['county_class_mean'])\n",
    "data['health_problem/county'] = data['health_problem']/(data['county_health_problem_mean'])\n",
    "data['family_status/county'] = data['family_status']/(data['county_family_status_mean'])\n",
    "data['leisure_sum/county'] = data['leisure_sum']/(data['county_leisure_sum_mean'])\n",
    "data['public_service_sum/county'] = data['public_service_sum']/(data['county_public_service_sum_mean'])\n",
    "data['trust_sum/county'] = data['trust_sum']/(data['county_trust_sum_mean'])\n",
    "\n",
    "#age   mean 246+ 13 =259\n",
    "data['age_income_mean'] = data.groupby(['age'])['income'].transform('mean').values\n",
    "data['age_family_income_mean'] = data.groupby(['age'])['family_income'].transform('mean').values\n",
    "data['age_equity_mean'] = data.groupby(['age'])['equity'].transform('mean').values\n",
    "data['age_depression_mean'] = data.groupby(['age'])['depression'].transform('mean').values\n",
    "data['age_floor_area_mean'] = data.groupby(['age'])['floor_area'].transform('mean').values\n",
    "data['age_health_mean'] = data.groupby(['age'])['health'].transform('mean').values\n",
    "data['age_class_10_diff_mean'] = data.groupby(['age'])['class_10_diff'].transform('mean').values\n",
    "data['age_class_mean'] = data.groupby(['age'])['class'].transform('mean').values\n",
    "data['age_health_problem_mean'] = data.groupby(['age'])['health_problem'].transform('mean').values\n",
    "data['age_family_status_mean'] = data.groupby(['age'])['family_status'].transform('mean').values\n",
    "data['age_leisure_sum_mean'] = data.groupby(['age'])['leisure_sum'].transform('mean').values\n",
    "data['age_public_service_sum_mean'] = data.groupby(['age'])['public_service_sum'].transform('mean').values\n",
    "data['age_trust_sum_mean'] = data.groupby(['age'])['trust_sum'].transform('mean').values\n",
    "\n",
    "# 和同龄人相比259 + 13 =272\n",
    "data['income/age'] = data['income']/(data['age_income_mean'])                                      \n",
    "data['family_income/age'] = data['family_income']/(data['age_family_income_mean'])   \n",
    "data['equity/age'] = data['equity']/(data['age_equity_mean'])       \n",
    "data['depression/age'] = data['depression']/(data['age_depression_mean'])                                                \n",
    "data['floor_area/age'] = data['floor_area']/(data['age_floor_area_mean'])\n",
    "data['health/age'] = data['health']/(data['age_health_mean'])\n",
    "data['class_10_diff/age'] = data['class_10_diff']/(data['age_class_10_diff_mean'])\n",
    "data['class/age'] = data['class']/(data['age_class_mean'])\n",
    "data['health_problem/age'] = data['health_problem']/(data['age_health_problem_mean'])\n",
    "data['family_status/age'] = data['family_status']/(data['age_family_status_mean'])\n",
    "data['leisure_sum/age'] = data['leisure_sum']/(data['age_leisure_sum_mean'])\n",
    "data['public_service_sum/age'] = data['public_service_sum']/(data['age_public_service_sum_mean'])\n",
    "data['trust_sum/age'] = data['trust_sum']/(data['age_trust_sum_mean'])\n",
    "\n",
    "\n",
    "print('shape',data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#272-9=263\n",
    "#删除数值特别少的和之前用过的特征\n",
    "del_list=['id','survey_time','edu_other','invest_other','property_other','join_party','province','city','county']\n",
    "use_feature = [clo for clo in data.columns if clo not in del_list]\n",
    "data.fillna(0,inplace=True) #还是补0\n",
    "train_shape = train.shape[0] #一共的数据量，训练集\n",
    "features = data[use_feature].columns #删除后所有的特征\n",
    "X_train_263 = data[:train_shape][use_feature].values\n",
    "y_train = target\n",
    "X_test_263 = data[train_shape:][use_feature].values\n",
    "X_train_263.shape #最终一种263个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 49)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_fea_49 = ['equity','depression','health','class','family_status','health_problem','class_10_after',\n",
    "           'equity/province','equity/city','equity/county',\n",
    "           'depression/province','depression/city','depression/county',\n",
    "           'health/province','health/city','health/county',\n",
    "           'class/province','class/city','class/county',\n",
    "           'family_status/province','family_status/city','family_status/county',\n",
    "           'family_income/province','family_income/city','family_income/county',\n",
    "           'floor_area/province','floor_area/city','floor_area/county',\n",
    "           'leisure_sum/province','leisure_sum/city','leisure_sum/county',\n",
    "           'public_service_sum/province','public_service_sum/city','public_service_sum/county',\n",
    "           'trust_sum/province','trust_sum/city','trust_sum/county',\n",
    "           'income/m','public_service_sum','class_diff','status_3_before','age_income_mean','age_floor_area_mean',\n",
    "           'weight_jin','height_cm',\n",
    "           'health/age','depression/age','equity/age','leisure_sum/age'\n",
    "          ]\n",
    "train_shape = train.shape[0]\n",
    "X_train_49 = data[:train_shape][imp_fea_49].values\n",
    "X_test_49 = data[train_shape:][imp_fea_49].values\n",
    "X_train_49.shape #最重要的49个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fea = ['survey_type','gender','nationality','edu_status','political','hukou','hukou_loc','work_exper','work_status','work_type',\n",
    "           'work_manage','marital','s_political','s_hukou','s_work_exper','s_work_status','s_work_type','f_political','f_work_14',\n",
    "           'm_political','m_work_14']\n",
    "noc_fea = [clo for clo in use_feature if clo not in cat_fea]\n",
    "\n",
    "len(noc_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10956, 141)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_data = data[cat_fea].values\n",
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "oh_data=enc.fit_transform(onehot_data).toarray()\n",
    "oh_data.shape #变为onehot编码格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 141)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_oh = oh_data[:train_shape,:]\n",
    "X_test_oh = oh_data[train_shape:,:]\n",
    "X_train_oh.shape #其中的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 383)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_383 = np.column_stack([data[:train_shape][noc_fea].values,X_train_oh])#先是noc，再是cat_fea\n",
    "X_test_383 = np.column_stack([data[train_shape:][noc_fea].values,X_test_oh])\n",
    "X_train_383.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.499466\tvalid_1's l2: 0.532217\n",
      "[1000]\ttraining's l2: 0.451208\tvalid_1's l2: 0.499767\n",
      "[1500]\ttraining's l2: 0.425452\tvalid_1's l2: 0.486572\n",
      "[2000]\ttraining's l2: 0.407381\tvalid_1's l2: 0.480365\n",
      "[2500]\ttraining's l2: 0.393181\tvalid_1's l2: 0.476804\n",
      "[3000]\ttraining's l2: 0.380986\tvalid_1's l2: 0.474885\n",
      "[3500]\ttraining's l2: 0.370309\tvalid_1's l2: 0.473485\n",
      "[4000]\ttraining's l2: 0.360462\tvalid_1's l2: 0.472775\n",
      "[4500]\ttraining's l2: 0.351506\tvalid_1's l2: 0.472081\n",
      "[5000]\ttraining's l2: 0.342976\tvalid_1's l2: 0.471686\n",
      "[5500]\ttraining's l2: 0.33498\tvalid_1's l2: 0.471207\n",
      "[6000]\ttraining's l2: 0.327418\tvalid_1's l2: 0.471073\n",
      "[6500]\ttraining's l2: 0.320207\tvalid_1's l2: 0.471274\n",
      "Early stopping, best iteration is:\n",
      "[5843]\ttraining's l2: 0.329705\tvalid_1's l2: 0.471027\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504101\tvalid_1's l2: 0.513714\n",
      "[1000]\ttraining's l2: 0.454879\tvalid_1's l2: 0.479581\n",
      "[1500]\ttraining's l2: 0.429138\tvalid_1's l2: 0.466092\n",
      "[2000]\ttraining's l2: 0.411134\tvalid_1's l2: 0.459137\n",
      "[2500]\ttraining's l2: 0.397103\tvalid_1's l2: 0.455425\n",
      "[3000]\ttraining's l2: 0.385257\tvalid_1's l2: 0.45265\n",
      "[3500]\ttraining's l2: 0.374586\tvalid_1's l2: 0.450239\n",
      "[4000]\ttraining's l2: 0.364815\tvalid_1's l2: 0.44912\n",
      "[4500]\ttraining's l2: 0.355906\tvalid_1's l2: 0.447995\n",
      "[5000]\ttraining's l2: 0.34741\tvalid_1's l2: 0.447237\n",
      "[5500]\ttraining's l2: 0.339488\tvalid_1's l2: 0.446183\n",
      "[6000]\ttraining's l2: 0.331867\tvalid_1's l2: 0.445874\n",
      "[6500]\ttraining's l2: 0.324635\tvalid_1's l2: 0.445052\n",
      "[7000]\ttraining's l2: 0.317723\tvalid_1's l2: 0.444484\n",
      "[7500]\ttraining's l2: 0.311116\tvalid_1's l2: 0.444305\n",
      "[8000]\ttraining's l2: 0.304637\tvalid_1's l2: 0.443675\n",
      "[8500]\ttraining's l2: 0.298397\tvalid_1's l2: 0.443555\n",
      "[9000]\ttraining's l2: 0.292424\tvalid_1's l2: 0.443216\n",
      "[9500]\ttraining's l2: 0.286642\tvalid_1's l2: 0.443125\n",
      "[10000]\ttraining's l2: 0.281079\tvalid_1's l2: 0.443205\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l2: 0.281079\tvalid_1's l2: 0.443205\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.503061\tvalid_1's l2: 0.517816\n",
      "[1000]\ttraining's l2: 0.455509\tvalid_1's l2: 0.480176\n",
      "[1500]\ttraining's l2: 0.430156\tvalid_1's l2: 0.463745\n",
      "[2000]\ttraining's l2: 0.412453\tvalid_1's l2: 0.454779\n",
      "[2500]\ttraining's l2: 0.398479\tvalid_1's l2: 0.449583\n",
      "[3000]\ttraining's l2: 0.386465\tvalid_1's l2: 0.446133\n",
      "[3500]\ttraining's l2: 0.375858\tvalid_1's l2: 0.444026\n",
      "[4000]\ttraining's l2: 0.365984\tvalid_1's l2: 0.442692\n",
      "[4500]\ttraining's l2: 0.356785\tvalid_1's l2: 0.441476\n",
      "[5000]\ttraining's l2: 0.348201\tvalid_1's l2: 0.440866\n",
      "[5500]\ttraining's l2: 0.340223\tvalid_1's l2: 0.440402\n",
      "[6000]\ttraining's l2: 0.332585\tvalid_1's l2: 0.440235\n",
      "[6500]\ttraining's l2: 0.325333\tvalid_1's l2: 0.439959\n",
      "[7000]\ttraining's l2: 0.318292\tvalid_1's l2: 0.440083\n",
      "Early stopping, best iteration is:\n",
      "[6411]\ttraining's l2: 0.326598\tvalid_1's l2: 0.439855\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504282\tvalid_1's l2: 0.512796\n",
      "[1000]\ttraining's l2: 0.455068\tvalid_1's l2: 0.477458\n",
      "[1500]\ttraining's l2: 0.428594\tvalid_1's l2: 0.465289\n",
      "[2000]\ttraining's l2: 0.410561\tvalid_1's l2: 0.459022\n",
      "[2500]\ttraining's l2: 0.396528\tvalid_1's l2: 0.455659\n",
      "[3000]\ttraining's l2: 0.384416\tvalid_1's l2: 0.453693\n",
      "[3500]\ttraining's l2: 0.373746\tvalid_1's l2: 0.452065\n",
      "[4000]\ttraining's l2: 0.364081\tvalid_1's l2: 0.450659\n",
      "[4500]\ttraining's l2: 0.355092\tvalid_1's l2: 0.449704\n",
      "[5000]\ttraining's l2: 0.346774\tvalid_1's l2: 0.449242\n",
      "[5500]\ttraining's l2: 0.338901\tvalid_1's l2: 0.448532\n",
      "[6000]\ttraining's l2: 0.331358\tvalid_1's l2: 0.448254\n",
      "[6500]\ttraining's l2: 0.324088\tvalid_1's l2: 0.447841\n",
      "[7000]\ttraining's l2: 0.317075\tvalid_1's l2: 0.447936\n",
      "Early stopping, best iteration is:\n",
      "[6626]\ttraining's l2: 0.322262\tvalid_1's l2: 0.44769\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.503216\tvalid_1's l2: 0.520153\n",
      "[1000]\ttraining's l2: 0.454578\tvalid_1's l2: 0.484716\n",
      "[1500]\ttraining's l2: 0.428579\tvalid_1's l2: 0.470354\n",
      "[2000]\ttraining's l2: 0.41041\tvalid_1's l2: 0.462978\n",
      "[2500]\ttraining's l2: 0.395945\tvalid_1's l2: 0.459382\n",
      "[3000]\ttraining's l2: 0.383636\tvalid_1's l2: 0.457687\n",
      "[3500]\ttraining's l2: 0.372634\tvalid_1's l2: 0.45677\n",
      "[4000]\ttraining's l2: 0.362785\tvalid_1's l2: 0.456109\n",
      "[4500]\ttraining's l2: 0.353693\tvalid_1's l2: 0.456029\n",
      "Early stopping, best iteration is:\n",
      "[4035]\ttraining's l2: 0.362069\tvalid_1's l2: 0.455995\n",
      "CV score: 0.45155440\n"
     ]
    }
   ],
   "source": [
    "##### lgb_263 #\n",
    "#lightGBM决策树\n",
    "lgb_263_param = {\n",
    "'num_leaves': 7, \n",
    "'min_data_in_leaf': 20, #叶子可能具有的最小记录数\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.003,\n",
    "\"boosting\": \"gbdt\", #用gbdt算法\n",
    "\"feature_fraction\": 0.18, #例如 0.18时，意味着在每次迭代中随机选择18％的参数来建树\n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.55, #每次迭代时用的数据比例\n",
    "\"bagging_seed\": 14,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l1\": 0.1005,\n",
    "\"lambda_l2\": 0.1996, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)   #交叉切分：5\n",
    "oof_lgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_lgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_263[val_idx], y_train[val_idx])#train:val=4:1\n",
    "\n",
    "    num_round = 10000\n",
    "    lgb_263 = lgb.train(lgb_263_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 800)\n",
    "    oof_lgb_263[val_idx] = lgb_263.predict(X_train_263[val_idx], num_iteration=lgb_263.best_iteration)\n",
    "    predictions_lgb_263 += lgb_263.predict(X_test_263, num_iteration=lgb_263.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x2016 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------特征重要性\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "df = pd.DataFrame(data[use_feature].columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(lgb_263.feature_importance())\n",
    "df = df.sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df.head(50))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:3.40431\tvalid_data-rmse:3.38326\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.406053\tvalid_data-rmse:0.705692\n",
      "[1000]\ttrain-rmse:0.271912\tvalid_data-rmse:0.708488\n",
      "Stopping. Best iteration:\n",
      "[518]\ttrain-rmse:0.400178\tvalid_data-rmse:0.705388\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:3.39808\tvalid_data-rmse:3.40794\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.406561\tvalid_data-rmse:0.691374\n",
      "[1000]\ttrain-rmse:0.27393\tvalid_data-rmse:0.692033\n",
      "Stopping. Best iteration:\n",
      "[585]\ttrain-rmse:0.379429\tvalid_data-rmse:0.690723\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:3.40186\tvalid_data-rmse:3.3931\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.411781\tvalid_data-rmse:0.660678\n",
      "[1000]\ttrain-rmse:0.274695\tvalid_data-rmse:0.663751\n",
      "Stopping. Best iteration:\n",
      "[492]\ttrain-rmse:0.414866\tvalid_data-rmse:0.660517\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:3.40241\tvalid_data-rmse:3.39014\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.411785\tvalid_data-rmse:0.664259\n",
      "[1000]\ttrain-rmse:0.274345\tvalid_data-rmse:0.665225\n",
      "Stopping. Best iteration:\n",
      "[597]\ttrain-rmse:0.381446\tvalid_data-rmse:0.663629\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:3.39343\tvalid_data-rmse:3.42628\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.418124\tvalid_data-rmse:0.650743\n",
      "[1000]\ttrain-rmse:0.282031\tvalid_data-rmse:0.65237\n",
      "Stopping. Best iteration:\n",
      "[766]\ttrain-rmse:0.339954\tvalid_data-rmse:0.64995\n",
      "\n",
      "CV score: 0.45476428\n"
     ]
    }
   ],
   "source": [
    "##### xgb_263\n",
    "#xgboost\n",
    "xgb_263_params = {'eta': 0.02,  #lr\n",
    "              'max_depth': 6,  \n",
    "              'min_child_weight':3,#最小叶子节点样本权重和\n",
    "              'gamma':0, #指定节点分裂所需的最小损失函数下降值。\n",
    "              'subsample': 0.7,  #控制对于每棵树，随机采样的比例\n",
    "              'colsample_bytree': 0.3,  #用来控制每棵随机采样的列数的占比 (每一列是一个特征)。\n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_xgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_263[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_263 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_263_params)\n",
    "    oof_xgb_263[val_idx] = xgb_263.predict(xgb.DMatrix(X_train_263[val_idx]), ntree_limit=xgb_263.best_ntree_limit)\n",
    "    predictions_xgb_263 += xgb_263.predict(xgb.DMatrix(X_test_263), ntree_limit=xgb_263.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.47786579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 1600 out of 1600 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#RandomForestRegressor随机森林\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_rfr_263 = np.zeros(len(X_train_263))\n",
    "predictions_rfr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    rfr_263 = rfr(n_estimators=1600,max_depth=9, min_samples_leaf=9, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.25,verbose=1,n_jobs=-1)\n",
    "    rfr_263.fit(tr_x,tr_y)\n",
    "    oof_rfr_263[val_idx] = rfr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_rfr_263 += rfr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_rfr_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6712           0.0031           16.36s\n",
      "         2           0.6596           0.0031           16.72s\n",
      "         3           0.6468           0.0033           16.41s\n",
      "         4           0.6600           0.0031           16.43s\n",
      "         5           0.6396           0.0031           16.43s\n",
      "         6           0.6339           0.0030           16.29s\n",
      "         7           0.6143           0.0033           16.28s\n",
      "         8           0.6305           0.0032           16.22s\n",
      "         9           0.6390           0.0027           16.16s\n",
      "        10           0.6196           0.0030           16.19s\n",
      "        20           0.6009           0.0024           15.71s\n",
      "        30           0.5589           0.0022           15.23s\n",
      "        40           0.5341           0.0015           14.77s\n",
      "        50           0.5290           0.0013           14.34s\n",
      "        60           0.4939           0.0011           13.92s\n",
      "        70           0.4772           0.0009           13.51s\n",
      "        80           0.4593           0.0007           13.10s\n",
      "        90           0.4427           0.0006           12.68s\n",
      "       100           0.4228           0.0005           12.27s\n",
      "       200           0.3413           0.0001            8.20s\n",
      "       300           0.2990           0.0000            4.10s\n",
      "       400           0.2764          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6622           0.0031           15.96s\n",
      "         2           0.6606           0.0033           16.52s\n",
      "         3           0.6688           0.0031           16.67s\n",
      "         4           0.6551           0.0032           16.73s\n",
      "         5           0.6367           0.0031           16.67s\n",
      "         6           0.6315           0.0031           16.55s\n",
      "         7           0.6515           0.0030           16.56s\n",
      "         8           0.6434           0.0028           16.51s\n",
      "         9           0.6276           0.0027           16.42s\n",
      "        10           0.6227           0.0028           16.38s\n",
      "        20           0.5614           0.0026           15.85s\n",
      "        30           0.5672           0.0019           15.40s\n",
      "        40           0.5222           0.0018           14.95s\n",
      "        50           0.5205           0.0012           14.49s\n",
      "        60           0.4812           0.0013           14.07s\n",
      "        70           0.4746           0.0012           13.67s\n",
      "        80           0.4498           0.0008           13.20s\n",
      "        90           0.4480           0.0007           12.79s\n",
      "       100           0.4471           0.0005           12.38s\n",
      "       200           0.3373           0.0001            8.20s\n",
      "       300           0.2905           0.0000            4.09s\n",
      "       400           0.2657          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6533           0.0032           17.15s\n",
      "         2           0.6530           0.0035           16.72s\n",
      "         3           0.6811           0.0030           16.54s\n",
      "         4           0.6303           0.0035           16.43s\n",
      "         5           0.6345           0.0031           16.20s\n",
      "         6           0.6687           0.0026           16.09s\n",
      "         7           0.6389           0.0032           16.17s\n",
      "         8           0.6352           0.0031           16.12s\n",
      "         9           0.6251           0.0030           16.12s\n",
      "        10           0.6466           0.0025           16.07s\n",
      "        20           0.5929           0.0027           15.69s\n",
      "        30           0.5528           0.0021           15.29s\n",
      "        40           0.5318           0.0016           14.90s\n",
      "        50           0.5109           0.0016           14.49s\n",
      "        60           0.4874           0.0012           14.07s\n",
      "        70           0.4712           0.0010           13.63s\n",
      "        80           0.4431           0.0008           13.20s\n",
      "        90           0.4278           0.0005           12.80s\n",
      "       100           0.4135           0.0006           12.36s\n",
      "       200           0.3367           0.0001            8.24s\n",
      "       300           0.2869           0.0000            4.11s\n",
      "       400           0.2664          -0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6505           0.0035           16.76s\n",
      "         2           0.6515           0.0032           17.12s\n",
      "         3           0.6518           0.0032           16.67s\n",
      "         4           0.6567           0.0032           16.63s\n",
      "         5           0.6541           0.0033           16.51s\n",
      "         6           0.6445           0.0033           16.48s\n",
      "         7           0.6252           0.0033           16.45s\n",
      "         8           0.6459           0.0029           16.42s\n",
      "         9           0.6305           0.0027           16.42s\n",
      "        10           0.6220           0.0027           16.38s\n",
      "        20           0.6101           0.0024           15.88s\n",
      "        30           0.5726           0.0019           15.48s\n",
      "        40           0.5282           0.0017           15.08s\n",
      "        50           0.5015           0.0013           14.60s\n",
      "        60           0.4871           0.0012           14.12s\n",
      "        70           0.4848           0.0009           13.74s\n",
      "        80           0.4431           0.0008           13.31s\n",
      "        90           0.4467           0.0007           12.85s\n",
      "       100           0.4196           0.0007           12.41s\n",
      "       200           0.3341           0.0000            8.16s\n",
      "       300           0.2855          -0.0001            4.04s\n",
      "       400           0.2696          -0.0000            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6601           0.0036           16.76s\n",
      "         2           0.6631           0.0028           16.72s\n",
      "         3           0.6740           0.0032           16.67s\n",
      "         4           0.6326           0.0032           16.43s\n",
      "         5           0.6398           0.0036           16.43s\n",
      "         6           0.6520           0.0033           16.42s\n",
      "         7           0.6510           0.0027           16.34s\n",
      "         8           0.6259           0.0030           16.22s\n",
      "         9           0.6235           0.0032           16.25s\n",
      "        10           0.6395           0.0029           16.15s\n",
      "        20           0.5981           0.0023           15.68s\n",
      "        30           0.5662           0.0020           15.24s\n",
      "        40           0.5250           0.0017           14.86s\n",
      "        50           0.5127           0.0014           14.41s\n",
      "        60           0.4888           0.0012           13.99s\n",
      "        70           0.4699           0.0010           13.56s\n",
      "        80           0.4617           0.0008           13.12s\n",
      "        90           0.4373           0.0008           12.70s\n",
      "       100           0.4321           0.0006           12.26s\n",
      "       200           0.3525           0.0002            8.17s\n",
      "       300           0.3012           0.0001            4.07s\n",
      "       400           0.2679          -0.0000            0.00s\n",
      "CV score: 0.45681016\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingRegressor梯度提升决策树\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_263 = np.zeros(train_shape)\n",
    "predictions_gbr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_263 = gbr(n_estimators=400, learning_rate=0.01,subsample=0.65,max_depth=7, min_samples_leaf=20,\n",
    "            max_features=0.22,verbose=1)\n",
    "    gbr_263.fit(tr_x,tr_y)\n",
    "    oof_gbr_263[val_idx] = gbr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_gbr_263 += gbr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.48643053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#ExtraTreesRegressor 极端随机森林回归\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_etr_263 = np.zeros(train_shape)\n",
    "predictions_etr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    etr_263 = etr(n_estimators=1000,max_depth=8, min_samples_leaf=12, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.4,verbose=1,n_jobs=-1)\n",
    "    etr_263.fit(tr_x,tr_y)\n",
    "    oof_etr_263[val_idx] = etr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_etr_263 += etr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_etr_263, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44863108329515455"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack2 = np.vstack([oof_lgb_263,oof_xgb_263,oof_gbr_263,oof_rfr_263,oof_etr_263]).transpose()\n",
    "test_stack2 = np.vstack([predictions_lgb_263, predictions_xgb_263,predictions_gbr_263,predictions_rfr_263,predictions_etr_263]).transpose()\n",
    "\n",
    "#交叉验证:5折，重复2次\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack2 = np.zeros(train_stack2.shape[0])\n",
    "predictions_lr2 = np.zeros(test_stack2.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack2,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack2[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack2[val_idx], target.iloc[val_idx].values\n",
    "    #Kernel Ridge Regression\n",
    "    lr2 = kr()\n",
    "    lr2.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack2[val_idx] = lr2.predict(val_data)\n",
    "    predictions_lr2 += lr2.predict(test_stack2) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.470708\tvalid_1's l2: 0.494106\n",
      "[2000]\ttraining's l2: 0.430764\tvalid_1's l2: 0.474849\n",
      "[3000]\ttraining's l2: 0.408276\tvalid_1's l2: 0.469683\n",
      "[4000]\ttraining's l2: 0.390394\tvalid_1's l2: 0.467867\n",
      "[5000]\ttraining's l2: 0.375102\tvalid_1's l2: 0.467172\n",
      "[6000]\ttraining's l2: 0.361259\tvalid_1's l2: 0.466773\n",
      "[7000]\ttraining's l2: 0.348568\tvalid_1's l2: 0.467015\n",
      "Early stopping, best iteration is:\n",
      "[6494]\ttraining's l2: 0.354893\tvalid_1's l2: 0.466688\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.471111\tvalid_1's l2: 0.493143\n",
      "[2000]\ttraining's l2: 0.430383\tvalid_1's l2: 0.47431\n",
      "[3000]\ttraining's l2: 0.407635\tvalid_1's l2: 0.469613\n",
      "[4000]\ttraining's l2: 0.389663\tvalid_1's l2: 0.467742\n",
      "[5000]\ttraining's l2: 0.374198\tvalid_1's l2: 0.466877\n",
      "Early stopping, best iteration is:\n",
      "[4939]\ttraining's l2: 0.375116\tvalid_1's l2: 0.466839\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.473697\tvalid_1's l2: 0.488271\n",
      "[2000]\ttraining's l2: 0.43289\tvalid_1's l2: 0.465181\n",
      "[3000]\ttraining's l2: 0.409732\tvalid_1's l2: 0.461306\n",
      "[4000]\ttraining's l2: 0.391906\tvalid_1's l2: 0.460649\n",
      "[5000]\ttraining's l2: 0.376497\tvalid_1's l2: 0.460902\n",
      "Early stopping, best iteration is:\n",
      "[4510]\ttraining's l2: 0.383801\tvalid_1's l2: 0.460496\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.467359\tvalid_1's l2: 0.507958\n",
      "[2000]\ttraining's l2: 0.427713\tvalid_1's l2: 0.490307\n",
      "[3000]\ttraining's l2: 0.405964\tvalid_1's l2: 0.484593\n",
      "[4000]\ttraining's l2: 0.388777\tvalid_1's l2: 0.481168\n",
      "[5000]\ttraining's l2: 0.373973\tvalid_1's l2: 0.479052\n",
      "[6000]\ttraining's l2: 0.360611\tvalid_1's l2: 0.477314\n",
      "[7000]\ttraining's l2: 0.348283\tvalid_1's l2: 0.47601\n",
      "[8000]\ttraining's l2: 0.336869\tvalid_1's l2: 0.475113\n",
      "[9000]\ttraining's l2: 0.326186\tvalid_1's l2: 0.474351\n",
      "[10000]\ttraining's l2: 0.316149\tvalid_1's l2: 0.47366\n",
      "[11000]\ttraining's l2: 0.306661\tvalid_1's l2: 0.473278\n",
      "[12000]\ttraining's l2: 0.29756\tvalid_1's l2: 0.472843\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[12000]\ttraining's l2: 0.29756\tvalid_1's l2: 0.472843\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.468228\tvalid_1's l2: 0.504214\n",
      "[2000]\ttraining's l2: 0.427636\tvalid_1's l2: 0.48661\n",
      "[3000]\ttraining's l2: 0.405127\tvalid_1's l2: 0.4825\n",
      "[4000]\ttraining's l2: 0.38731\tvalid_1's l2: 0.480712\n",
      "[5000]\ttraining's l2: 0.372171\tvalid_1's l2: 0.479826\n",
      "[6000]\ttraining's l2: 0.358405\tvalid_1's l2: 0.479297\n",
      "[7000]\ttraining's l2: 0.345934\tvalid_1's l2: 0.479015\n",
      "[8000]\ttraining's l2: 0.334267\tvalid_1's l2: 0.478824\n",
      "Early stopping, best iteration is:\n",
      "[7993]\ttraining's l2: 0.334342\tvalid_1's l2: 0.478799\n",
      "CV score: 0.46913138\n"
     ]
    }
   ],
   "source": [
    "##### lgb_49\n",
    "lgb_49_param = {\n",
    "'num_leaves': 9,\n",
    "'min_data_in_leaf': 23,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.002,\n",
    "\"boosting\": \"gbdt\",\n",
    "\"feature_fraction\": 0.45,\n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.65,\n",
    "\"bagging_seed\": 15,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)   \n",
    "oof_lgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_lgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 12000\n",
    "    lgb_49 = lgb.train(lgb_49_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n",
    "    oof_lgb_49[val_idx] = lgb_49.predict(X_train_49[val_idx], num_iteration=lgb_49.best_iteration)\n",
    "    predictions_lgb_49 += lgb_49.predict(X_test_49, num_iteration=lgb_49.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:3.40422\tvalid_data-rmse:3.38325\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.526689\tvalid_data-rmse:0.718885\n",
      "[1000]\ttrain-rmse:0.435378\tvalid_data-rmse:0.720057\n",
      "Stopping. Best iteration:\n",
      "[601]\ttrain-rmse:0.506178\tvalid_data-rmse:0.71807\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:3.39825\tvalid_data-rmse:3.40774\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.528483\tvalid_data-rmse:0.702569\n",
      "[1000]\ttrain-rmse:0.438964\tvalid_data-rmse:0.703725\n",
      "Stopping. Best iteration:\n",
      "[600]\ttrain-rmse:0.509122\tvalid_data-rmse:0.701568\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:3.40192\tvalid_data-rmse:3.39291\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.532097\tvalid_data-rmse:0.66724\n",
      "[1000]\ttrain-rmse:0.439403\tvalid_data-rmse:0.669937\n",
      "Stopping. Best iteration:\n",
      "[457]\ttrain-rmse:0.54151\tvalid_data-rmse:0.666551\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:3.40243\tvalid_data-rmse:3.39011\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.532917\tvalid_data-rmse:0.681207\n",
      "[1000]\ttrain-rmse:0.441171\tvalid_data-rmse:0.683234\n",
      "Stopping. Best iteration:\n",
      "[468]\ttrain-rmse:0.539639\tvalid_data-rmse:0.680601\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:3.39341\tvalid_data-rmse:3.42628\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 600 rounds.\n",
      "[500]\ttrain-rmse:0.535086\tvalid_data-rmse:0.66088\n",
      "[1000]\ttrain-rmse:0.441165\tvalid_data-rmse:0.662499\n",
      "Stopping. Best iteration:\n",
      "[533]\ttrain-rmse:0.527742\tvalid_data-rmse:0.660197\n",
      "\n",
      "CV score: 0.47024327\n"
     ]
    }
   ],
   "source": [
    "##### xgb_49\n",
    "xgb_49_params = {'eta': 0.02, \n",
    "              'max_depth': 5, \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.35, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_xgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_49 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_49_params)\n",
    "    oof_xgb_49[val_idx] = xgb_49.predict(xgb.DMatrix(X_train_49[val_idx]), ntree_limit=xgb_49.best_ntree_limit)\n",
    "    predictions_xgb_49 += xgb_49.predict(xgb.DMatrix(X_test_49), ntree_limit=xgb_49.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6720           0.0036           17.37s\n",
      "         2           0.6633           0.0032           17.34s\n",
      "         3           0.6653           0.0032           15.32s\n",
      "         4           0.6495           0.0032           14.01s\n",
      "         5           0.6472           0.0031           13.21s\n",
      "         6           0.6630           0.0030           12.77s\n",
      "         7           0.6465           0.0029           12.54s\n",
      "         8           0.6401           0.0028           12.28s\n",
      "         9           0.6299           0.0027           12.08s\n",
      "        10           0.6412           0.0028           11.86s\n",
      "        20           0.6080           0.0024           10.90s\n",
      "        30           0.5792           0.0018           10.43s\n",
      "        40           0.5644           0.0014           10.09s\n",
      "        50           0.5334           0.0013            9.79s\n",
      "        60           0.5199           0.0011            9.56s\n",
      "        70           0.5042           0.0009            9.36s\n",
      "        80           0.4765           0.0009            9.15s\n",
      "        90           0.4836           0.0006            8.94s\n",
      "       100           0.4562           0.0004            8.75s\n",
      "       200           0.3948           0.0001            6.91s\n",
      "       300           0.3628          -0.0001            5.16s\n",
      "       400           0.3481           0.0000            3.43s\n",
      "       500           0.3348           0.0000            1.71s\n",
      "       600           0.3174          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6700           0.0032            9.58s\n",
      "         2           0.6653           0.0030            9.87s\n",
      "         3           0.6758           0.0030            9.95s\n",
      "         4           0.6618           0.0033            9.98s\n",
      "         5           0.6395           0.0034           10.00s\n",
      "         6           0.6570           0.0030           10.10s\n",
      "         7           0.6353           0.0032           10.08s\n",
      "         8           0.6332           0.0030           10.21s\n",
      "         9           0.6286           0.0030           10.24s\n",
      "        10           0.6216           0.0028           10.21s\n",
      "        20           0.6037           0.0024            9.95s\n",
      "        30           0.5566           0.0022            9.82s\n",
      "        40           0.5381           0.0018            9.67s\n",
      "        50           0.5245           0.0012            9.48s\n",
      "        60           0.5049           0.0010            9.32s\n",
      "        70           0.5005           0.0010            9.13s\n",
      "        80           0.4694           0.0007            8.94s\n",
      "        90           0.4697           0.0005            8.76s\n",
      "       100           0.4600           0.0005            8.59s\n",
      "       200           0.3940           0.0001            6.85s\n",
      "       300           0.3686          -0.0000            5.13s\n",
      "       400           0.3513          -0.0000            3.42s\n",
      "       500           0.3260          -0.0000            1.71s\n",
      "       600           0.3199          -0.0001            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6784           0.0031            9.58s\n",
      "         2           0.6559           0.0033            9.86s\n",
      "         3           0.6418           0.0033            9.95s\n",
      "         4           0.6584           0.0031            9.83s\n",
      "         5           0.6407           0.0033            9.88s\n",
      "         6           0.6419           0.0029            9.90s\n",
      "         7           0.6336           0.0032           10.00s\n",
      "         8           0.6329           0.0030           10.14s\n",
      "         9           0.6361           0.0029           10.11s\n",
      "        10           0.6423           0.0025           10.09s\n",
      "        20           0.6071           0.0022            9.93s\n",
      "        30           0.5703           0.0020            9.81s\n",
      "        40           0.5587           0.0014            9.64s\n",
      "        50           0.5259           0.0014            9.44s\n",
      "        60           0.4960           0.0011            9.27s\n",
      "        70           0.5025           0.0009            9.10s\n",
      "        80           0.4592           0.0008            8.92s\n",
      "        90           0.4724           0.0006            8.74s\n",
      "       100           0.4584           0.0006            8.58s\n",
      "       200           0.3967           0.0001            6.85s\n",
      "       300           0.3522          -0.0000            5.12s\n",
      "       400           0.3386          -0.0000            3.42s\n",
      "       500           0.3266          -0.0001            1.71s\n",
      "       600           0.3088          -0.0001            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6509           0.0034           10.19s\n",
      "         2           0.6643           0.0032           10.17s\n",
      "         3           0.6593           0.0035           10.15s\n",
      "         4           0.6493           0.0032           10.28s\n",
      "         5           0.6358           0.0032           10.12s\n",
      "         6           0.6453           0.0029           10.10s\n",
      "         7           0.6366           0.0031           10.16s\n",
      "         8           0.6571           0.0028           10.14s\n",
      "         9           0.6261           0.0029           10.18s\n",
      "        10           0.6397           0.0026           10.15s\n",
      "        20           0.6066           0.0022            9.98s\n",
      "        30           0.5687           0.0021            9.78s\n",
      "        40           0.5579           0.0015            9.62s\n",
      "        50           0.5297           0.0014            9.46s\n",
      "        60           0.4954           0.0011            9.30s\n",
      "        70           0.4942           0.0009            9.12s\n",
      "        80           0.4794           0.0008            8.95s\n",
      "        90           0.4849           0.0006            8.78s\n",
      "       100           0.4574           0.0006            8.60s\n",
      "       200           0.3981           0.0001            6.85s\n",
      "       300           0.3697          -0.0001            5.14s\n",
      "       400           0.3438          -0.0000            3.42s\n",
      "       500           0.3233          -0.0000            1.71s\n",
      "       600           0.3089          -0.0001            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6636           0.0032           10.18s\n",
      "         2           0.6662           0.0033           10.17s\n",
      "         3           0.6586           0.0034           10.15s\n",
      "         4           0.6593           0.0028           10.13s\n",
      "         5           0.6375           0.0031           10.11s\n",
      "         6           0.6637           0.0030           10.20s\n",
      "         7           0.6480           0.0028           10.08s\n",
      "         8           0.6441           0.0029           10.21s\n",
      "         9           0.6354           0.0028           10.18s\n",
      "        10           0.6251           0.0030           10.15s\n",
      "        20           0.6201           0.0022           10.06s\n",
      "        30           0.5713           0.0018            9.86s\n",
      "        40           0.5443           0.0017            9.67s\n",
      "        50           0.5351           0.0013            9.51s\n",
      "        60           0.5111           0.0013            9.32s\n",
      "        70           0.4901           0.0009            9.12s\n",
      "        80           0.4744           0.0007            8.95s\n",
      "        90           0.4639           0.0006            8.76s\n",
      "       100           0.4557           0.0005            8.59s\n",
      "       200           0.3923           0.0001            6.83s\n",
      "       300           0.3724           0.0000            5.12s\n",
      "       400           0.3516          -0.0001            3.41s\n",
      "       500           0.3297          -0.0001            1.71s\n",
      "       600           0.3159          -0.0000            0.00s\n",
      "CV score: 0.47056491\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_49 = np.zeros(train_shape)\n",
    "predictions_gbr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_49 = gbr(n_estimators=600, learning_rate=0.01,subsample=0.65,max_depth=6, min_samples_leaf=20,\n",
    "            max_features=0.35,verbose=1)\n",
    "    gbr_49.fit(tr_x,tr_y)\n",
    "    oof_gbr_49[val_idx] = gbr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_gbr_49 += gbr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46732106438119714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack3 = np.vstack([oof_lgb_49,oof_xgb_49,oof_gbr_49]).transpose()\n",
    "test_stack3 = np.vstack([predictions_lgb_49, predictions_xgb_49,predictions_gbr_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack3 = np.zeros(train_stack3.shape[0])\n",
    "predictions_lr3 = np.zeros(test_stack3.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack3,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack3[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack3[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr3 = kr()\n",
    "    lr3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack3[val_idx] = lr3.predict(val_data)\n",
    "    predictions_lr3 += lr3.predict(test_stack3) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.52281358\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_383 = np.zeros(train_shape)\n",
    "predictions_kr_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #Kernel Ridge Regression 岭回归\n",
    "    kr_383 = kr()\n",
    "    kr_383.fit(tr_x,tr_y)\n",
    "    oof_kr_383[val_idx] = kr_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_kr_383 += kr_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48687670\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_383 = np.zeros(train_shape)\n",
    "predictions_ridge_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #使用岭回归\n",
    "    ridge_383 = Ridge(alpha=1200)\n",
    "    ridge_383.fit(tr_x,tr_y)\n",
    "    oof_ridge_383[val_idx] = ridge_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_ridge_383 += ridge_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53296555\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_383 = np.zeros(train_shape)\n",
    "predictions_en_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #ElasticNet 弹性网络\n",
    "    en_383 = en(alpha=1.0,l1_ratio=0.06)\n",
    "    en_383.fit(tr_x,tr_y)\n",
    "    oof_en_383[val_idx] = en_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_en_383 += en_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48717341\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_383 = np.zeros(train_shape)\n",
    "predictions_br_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #BayesianRidge 贝叶斯回归\n",
    "    br_383 = br()\n",
    "    br_383.fit(tr_x,tr_y)\n",
    "    oof_br_383[val_idx] = br_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_br_383 += br_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48773361014523725"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack1 = np.vstack([oof_br_383,oof_kr_383,oof_en_383,oof_ridge_383]).transpose()\n",
    "test_stack1 = np.vstack([predictions_br_383, predictions_kr_383,predictions_en_383,predictions_ridge_383]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack1 = np.zeros(train_stack1.shape[0])\n",
    "predictions_lr1 = np.zeros(test_stack1.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack1,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack1[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack1[val_idx], target.iloc[val_idx].values\n",
    "    # LinearRegression简单的线性回归\n",
    "    lr1 = lr()\n",
    "    lr1.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack1[val_idx] = lr1.predict(val_data)\n",
    "    predictions_lr1 += lr1.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.50254180\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_49 = np.zeros(train_shape)\n",
    "predictions_kr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_49 = kr()\n",
    "    kr_49.fit(tr_x,tr_y)\n",
    "    oof_kr_49[val_idx] = kr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_kr_49 += kr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49451286\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_49 = np.zeros(train_shape)\n",
    "predictions_ridge_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_49 = Ridge(alpha=6)\n",
    "    ridge_49.fit(tr_x,tr_y)\n",
    "    oof_ridge_49[val_idx] = ridge_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_ridge_49 += ridge_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49534595\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_49 = np.zeros(train_shape)\n",
    "predictions_br_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_49 = br()\n",
    "    br_49.fit(tr_x,tr_y)\n",
    "    oof_br_49[val_idx] = br_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_br_49 += br_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53841695\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_49 = np.zeros(train_shape)\n",
    "predictions_en_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_49 = en(alpha=1.0,l1_ratio=0.05)\n",
    "    en_49.fit(tr_x,tr_y)\n",
    "    oof_en_49[val_idx] = en_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_en_49 += en_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4949151048252919"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack4 = np.vstack([oof_br_49,oof_kr_49,oof_en_49,oof_ridge_49]).transpose()\n",
    "test_stack4 = np.vstack([predictions_br_49, predictions_kr_49,predictions_en_49,predictions_ridge_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack4 = np.zeros(train_stack4.shape[0])\n",
    "predictions_lr4 = np.zeros(test_stack4.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack4,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack4[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack4[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr4 = lr()\n",
    "    lr4.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack4[val_idx] = lr4.predict(val_data)\n",
    "    predictions_lr4 += lr4.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4533257568658398"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(target.values, 0.7*(0.6*oof_stack2 + 0.4*oof_stack3)+0.3*(0.55*oof_stack1+0.45*oof_stack4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4486388082550748"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack5 = np.vstack([oof_stack1,oof_stack2,oof_stack3,oof_stack4]).transpose()\n",
    "test_stack5 = np.vstack([predictions_lr1, predictions_lr2,predictions_lr3,predictions_lr4]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack5 = np.zeros(train_stack5.shape[0])\n",
    "predictions_lr5= np.zeros(test_stack5.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack5,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack5[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack5[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    lr5 = lr()\n",
    "    lr5.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack5[val_idx] = lr5.predict(val_data)\n",
    "    predictions_lr5 += lr5.predict(test_stack5) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.879954\n",
       "std         0.463116\n",
       "min         1.624530\n",
       "25%         3.663965\n",
       "50%         3.950512\n",
       "75%         4.188898\n",
       "max         5.025322\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example = pd.read_csv('happiness_submit.csv',sep=',',encoding='latin-1')\n",
    "\n",
    "submit_example['happiness'] = predictions_lr5\n",
    "\n",
    "submit_example.happiness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.879968\n",
       "std         0.462986\n",
       "min         1.624530\n",
       "25%         3.663965\n",
       "50%         3.950512\n",
       "75%         4.188898\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example.loc[submit_example['happiness']>4.96,'happiness']= 5\n",
    "submit_example.loc[submit_example['happiness']<=1.04,'happiness']= 1\n",
    "submit_example.loc[(submit_example['happiness']>1.96)&(submit_example['happiness']<2.04),'happiness']= 2\n",
    "# submit_example.loc[(submit_example['happiness']>2.99)&(submit_example['happiness']<3.01),'happiness']= 3\n",
    "# submit_example.loc[(submit_example['happiness']>3.99)&(submit_example['happiness']<4.01),'happiness']= 4\n",
    "\n",
    "submit_example.to_csv(\"submision.csv\",index=False)\n",
    "submit_example.happiness.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
